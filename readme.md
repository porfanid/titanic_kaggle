# Titanic Prediction Project

This project is a machine learning pipeline developed in Python for predicting survival on the Kaggle Titanic dataset. The main processing script is in `main.py`.

## Overview

- **Data Processing:**  
  The script reads the Titanic dataset, cleans data, and engineers features including text features from Name, Ticket, and Cabin using TF-IDF.

- **Feature Engineering:**  
  The code extracts numerical and categorical features from the dataset, applies label encoding and standard scaling, and creates text features for model training.

- **Model Training:**  
  Two algorithms (Random Forest and Gradient Boosting) are trained and evaluated using AUC and Accuracy. The best-performing model is selected based on its AUC score.

- **Prediction and Submission:**  
  The chosen model is used to predict the survival of test data and a submission CSV file is created for Kaggle.

## Installation

1. Ensure you have Python installed.
2. Install dependencies using:

   ```bash
   pip install -r requirements.txt
   ```

## Usage

Run the main script with:

```bash
python main.py
```

The script will process data, train models, evaluate performance, and create a submission file named `improved_submission.csv`.

## Project Structure

- `main.py`  
  Contains the full pipeline including data processing, feature engineering, model training, and prediction.
  
- `improved_submission.csv`  
  The output file with predictions generated by the model.

- `readme.md`  
  This file.

Make sure to have your dataset CSV files in the expected locations as specified in the code.

## Notes

- The project is built using Python and managed with `pip`.
- It is intended for submission as a submission to the Kaggle project named [Titanic](https://www.kaggle.com/competitions/titanic) prediction.